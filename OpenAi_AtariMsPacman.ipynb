{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAi AtariMsPacman.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbarker6706/Portfolio2/blob/master/OpenAi_AtariMsPacman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsSGgH2Y0apl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#          _____                _____                    _____                    _____                    _____                    _____          \n",
        "#         /\\    \\              /\\    \\                  /\\    \\                  /\\    \\                  /\\    \\                  /\\    \\         \n",
        "#        /::\\    \\            /::\\    \\                /::\\    \\                /::\\    \\                /::\\    \\                /::\\    \\        \n",
        "#       /::::\\    \\           \\:::\\    \\              /::::\\    \\              /::::\\    \\              /::::\\    \\               \\:::\\    \\       \n",
        "#      /::::::\\    \\           \\:::\\    \\            /::::::\\    \\            /::::::\\    \\            /::::::\\    \\               \\:::\\    \\      \n",
        "#     /:::/\\:::\\    \\           \\:::\\    \\          /:::/\\:::\\    \\          /:::/\\:::\\    \\          /:::/\\:::\\    \\               \\:::\\    \\     \n",
        "#    /:::/__\\:::\\    \\           \\:::\\    \\        /:::/__\\:::\\    \\        /:::/__\\:::\\    \\        /:::/__\\:::\\    \\               \\:::\\    \\    \n",
        "#    \\:::\\   \\:::\\    \\          /::::\\    \\      /::::\\   \\:::\\    \\      /::::\\   \\:::\\    \\      /::::\\   \\:::\\    \\              /::::\\    \\   \n",
        "#  ___\\:::\\   \\:::\\    \\        /::::::\\    \\    /::::::\\   \\:::\\    \\    /::::::\\   \\:::\\    \\    /::::::\\   \\:::\\    \\    ____    /::::::\\    \\  \n",
        "# /\\   \\:::\\   \\:::\\    \\      /:::/\\:::\\    \\  /:::/\\:::\\   \\:::\\    \\  /:::/\\:::\\   \\:::\\____\\  /:::/\\:::\\   \\:::\\    \\  /\\   \\  /:::/\\:::\\    \\ \n",
        "#/::\\   \\:::\\   \\:::\\____\\    /:::/  \\:::\\____\\/:::/  \\:::\\   \\:::\\____\\/:::/  \\:::\\   \\:::|    |/:::/  \\:::\\   \\:::\\____\\/::\\   \\/:::/  \\:::\\____\\\n",
        "#\\:::\\   \\:::\\   \\::/    /   /:::/    \\::/    /\\::/    \\:::\\  /:::/    /\\::/   |::::\\  /:::|____|\\::/    \\:::\\  /:::/    /\\:::\\  /:::/    \\::/    /\n",
        "# \\:::\\   \\:::\\   \\/____/   /:::/    / \\/____/  \\/____/ \\:::\\/:::/    /  \\/____|:::::\\/:::/    /  \\/____/ \\:::\\/:::/    /  \\:::\\/:::/    / \\/____/ \n",
        "#  \\:::\\   \\:::\\    \\      /:::/    /                    \\::::::/    /         |:::::::::/    /            \\::::::/    /    \\::::::/    /          \n",
        "#   \\:::\\   \\:::\\____\\    /:::/    /                      \\::::/    /          |::|\\::::/    /              \\::::/    /      \\::::/____/           \n",
        "#    \\:::\\  /:::/    /    \\::/    /                       /:::/    /           |::| \\::/____/               /:::/    /        \\:::\\    \\           \n",
        "#     \\:::\\/:::/    /      \\/____/                       /:::/    /            |::|  ~|                    /:::/    /          \\:::\\    \\          \n",
        "#      \\::::::/    /                                    /:::/    /             |::|   |                   /:::/    /            \\:::\\    \\         \n",
        "#       \\::::/    /                                    /:::/    /              \\::|   |                  /:::/    /              \\:::\\____\\        \n",
        "#        \\::/    /                                     \\::/    /                \\:|   |                  \\::/    /                \\::/    /        \n",
        "#         \\/____/                                       \\/____/                  \\|___|                   \\/____/                  \\/____/    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odNaDE1zyrL2",
        "colab_type": "text"
      },
      "source": [
        "# install dependancies, takes around 45 seconds\n",
        "\n",
        "Rendering Dependancies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-AxnvAVyzQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A-1LTSH88EE",
        "colab_type": "text"
      },
      "source": [
        "Pacman Dependancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCelFzWY9MBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APXSx7hg19TH",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdb2JwZy4jGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQEtc28G4niA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9UWeToN4r7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3BGbWOu179M",
        "colab_type": "text"
      },
      "source": [
        "# Pacman!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGEFMfDOzLen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = wrap_env(gym.make(\"MsPacman-v0\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BmIlXhe9Q89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check out the pacman action space!\n",
        "print(env.action_space.n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikGQ8yYTWHNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env.env.get_action_meanings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nj5sjsk15IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observation = env.reset()\n",
        "\n",
        "while True:\n",
        "  \n",
        "    env.render()\n",
        "    \n",
        "    #your agent goes here\n",
        "    action = env.action_space.sample() \n",
        "         \n",
        "    observation, reward, done, info = env.step(action) \n",
        "        \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUa7MdJSTqXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "observationspace= 210*160 #height and width of Ms. Pacman\n",
        "Q = np.zeros([observationspace, env.action_space.n])\n",
        "\n",
        "G=0 #reward accumulator\n",
        "alpha = .618 #learning rate \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RiQL_-_bIfpR",
        "colab": {}
      },
      "source": [
        "observation = env.reset()\n",
        "  \n",
        "env.render()\n",
        "    \n",
        "#your agent goes here\n",
        "for episode in range(1,1001):\n",
        "    done = False\n",
        "    G, reward = 0,0\n",
        "    state = env.reset()\n",
        "    while done != True:\n",
        "        action = np.argmax(Q[state]) #1\n",
        "        state2, reward, done, info = env.step(action) #2\n",
        "        Q[state,action] += alpha * (reward + np.max(Q[state2]) - Q[state,action]) #3\n",
        "        G += reward\n",
        "        state = state2   \n",
        "    if episode % 50 == 0:\n",
        "        print('Episode {} Total Reward: {}'.format(episode,G))            \n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIB6gUekFNx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np \n",
        "# 1. Load Environment and Q-table structure\n",
        "env = gym.make('FrozenLake8x8-v0')\n",
        "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
        "# env.obeservation.n, env.action_space.n gives number of states and action in env loaded\n",
        "# 2. Parameters of Q-leanring\n",
        "eta = .628\n",
        "gma = .9\n",
        "epis = 5000\n",
        "rev_list = [] # rewards per episode calculate\n",
        "# 3. Q-learning Algorithm\n",
        "for i in range(epis):\n",
        "    # Reset environment\n",
        "    s = env.reset()\n",
        "    rAll = 0\n",
        "    d = False\n",
        "    j = 0\n",
        "    #The Q-Table learning algorithm\n",
        "    while j < 99:\n",
        "        env.render()\n",
        "        j+=1\n",
        "        # Choose action from Q table\n",
        "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
        "        #Get new state & reward from environment\n",
        "        s1,r,d,_ = env.step(a)\n",
        "        #Update Q-Table with new knowledge\n",
        "        Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])\n",
        "        rAll += r\n",
        "        s = s1\n",
        "        if d == True:\n",
        "            break\n",
        "    rev_list.append(rAll)\n",
        "    env.render()\n",
        "print(\"Reward Sum on all episodes \" + str(sum(rev_list)/epis))\n",
        "print(\"Final Values Q-Table\")\n",
        "print(Q)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}